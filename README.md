# ğŸ§  OAMI â€” Options-Aware Market Intelligence  
**Version:** 0.3.0  
**License:** MIT  
**Author:** skyliquid22  

---

## ğŸ“˜ Overview
OAMI (Options-Aware Market Intelligence) is a **modular, machine-learning-ready framework** for analyzing equities and options data.  
It fetches, caches, and processes both **market** and **options chain** data to engineer advanced quantitative features for trading strategy research.

Built for:
- Data scientists and quants who want to explore market microstructure & sentiment  
- ML practitioners building predictive models using market and options signals  
- Researchers studying the relationships between implied volatility, returns, and risk  

---

## âš™ï¸ Core Features
- ğŸ§© **Market Data Layer** â€” Robust Polygon.io integration with retry logic, caching, and error handling  
- ğŸ’¾ **HDF5 Cache** â€” Consolidated store at `data/cache/oami_store.h5` for both market bars and per-contract aggregates  
- ğŸ§® **Feature Engineering** â€” SMA, EMA, RSI, MACD, Bollinger Bands, ATR, lags, rolling stats  
- ğŸ“Š **Options Sentiment** â€” Put/Call ratios, OI ratios, rolling vol metrics, sentiment index  
- ğŸ”— **Cross-Asset Context (v0.3)** â€” SPY/QQQ/VIX correlation and beta placeholders (to be expanded)  
- ğŸ§  **Advanced Features** â€” PCA-based dimensional reduction and implied volatility structures  
- ğŸ§° **Config-Driven Design** â€” YAML-based control over parameters and feature toggles  
- ğŸ§ª **Testing & CI/CD** â€” Full Pytest suite with GitHub Actions integration  

---

## ğŸ§± Architecture

```mermaid
graph LR
    A[Polygon API] --> B[Data Layer]
    B --> C[HDF5 Cache]
    C --> D[Feature Builder]
    C --> E[Options Sentiment]
    D --> F[Dataset Builder]
    E --> F
    F --> G[Advanced Features]
    G --> H[Modeling and Evaluation]
```

Each module communicates through standardized Pandas DataFrames and supports both **live API** and **offline CSV** data.

---

## ğŸ“‚ Project Structure
```
OAMI_v0.3.0/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ config.yaml
â”‚   â””â”€â”€ logging_config.json
â”œâ”€â”€ data/
â”‚   â””â”€â”€ cache/
â”‚       â””â”€â”€ oami_store.h5
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 00_data_ingestion_demo.ipynb
â”‚   â”œâ”€â”€ 01_feature_importance.ipynb
â”‚   â””â”€â”€ 02_advanced_features.ipynb
â”œâ”€â”€ src/
â”‚   â””â”€â”€ oami/
â”‚       â”œâ”€â”€ data_layer.py
â”‚       â”œâ”€â”€ features.py
â”‚       â”œâ”€â”€ dataset.py
â”‚       â”œâ”€â”€ features_crossasset.py
â”‚       â”œâ”€â”€ features_select.py
â”‚       â””â”€â”€ features_advanced.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_features.py
â”‚   â”œâ”€â”€ test_options_features.py
â”‚   â”œâ”€â”€ test_dataset.py
â”‚   â””â”€â”€ resources/
â”‚       â”œâ”€â”€ market_sample.csv
â”‚       â””â”€â”€ options_sample.csv
â”œâ”€â”€ .github/workflows/tests.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.cfg
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸš€ Quickstart

### 1ï¸âƒ£ Clone the Repository
```bash
git clone git@github.com:skyliquid22/OAMI.git
cd OAMI
```

### 2ï¸âƒ£ Create a Virtual Environment
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
pip install -r requirements-dev.txt
```

### 3ï¸âƒ£ Set Your Environment Variable
```bash
export POLYGON_API_KEY="your_real_polygon_api_key"
```

### 4ï¸âƒ£ Run Tests
```bash
pytest --maxfail=1 --disable-warnings --cov=src/oami --cov-report=term-missing
```

### 5ï¸âƒ£ Run the Main Pipeline
```bash
python -m src.main
```

This will automatically:
- load cached sample data (SPY & SPY options)
- generate feature sets
- build unified dataset
- log outputs in `./logs/oami.log`

---

## ğŸ“ˆ Example Workflow (Python)
```python
from oami.data_layer import get_market_data, get_options_data
from oami.features_advanced import AdvancedFeatureBuilder

market = get_market_data("SPY", "2024-01-01", "2024-06-30")
contracts = get_options_data("SPY", "2024-01-01", "2024-06-30")

afb = AdvancedFeatureBuilder(market, contracts)
df = (afb
      .add_crossasset(benchmarks=["SPY", "VIX"])
      .add_options_implied()
      .apply_selection(n_components=5)
      .finalize())

print(df.head())
```

---

## ğŸ§ª Testing & Quality
- **Framework:** `pytest`
- **Coverage:** 75% minimum (enforced via `setup.cfg`)
- **Linting:** `flake8`, `black`, `isort`
- **CI:** GitHub Actions (`.github/workflows/tests.yml`)

Run all checks locally:
```bash
black src tests
isort src tests
flake8 src tests
pytest
```

---

## ğŸ§­ Roadmap
| Milestone | Description |
|------------|--------------|
| **v0.3.1** | Implement real cross-asset correlations (SPY, QQQ, VIX) |
| **v0.3.2** | Add volatility features (rolling std, drawdown, clustering index) |
| **v0.3.3** | Integrate feature importance across ML models |
| **v0.4.0** | Launch model training & backtesting pipeline |
| **v0.5.0** | Deploy real-time async data stream and queue processing |

---

## ğŸ“œ License
MIT License Â© 2025 [skyliquid22](https://github.com/skyliquid22)

---

## ğŸ’¬ Acknowledgments
- [Polygon.io](https://polygon.io) â€” for data access APIs  
- [TA-Lib / Technical Analysis Library](https://github.com/bukosabino/ta) â€” for indicator functions  
- [Scikit-Learn](https://scikit-learn.org/) â€” for PCA, RFE, and feature selection tools  
- [XGBoost](https://xgboost.readthedocs.io/) â€” for advanced model integration  

---

## ğŸ§© Maintainer Notes
- All caching and feature generation is **configurable via `configs/config.yaml`**
- Default data is offline (SPY, 3-month sample) for reproducibility
- Uses a JSON-based logger (`logging_config.py`) compatible with log collectors and MLFlow

---

> _â€œThe future belongs to those who quantify uncertainty.â€_
