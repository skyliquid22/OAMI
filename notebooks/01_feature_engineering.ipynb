{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7ea2c99",
   "metadata": {},
   "source": [
    "# 01 — Feature Engineering (Market + Options Sentiment)\n",
    "\n",
    "This notebook builds a **feature-rich dataset** by combining:\n",
    "- technical indicators from market data (via `ta`), and\n",
    "- options-based sentiment features (put/call, OI skew, rolling stats).\n",
    "\n",
    "We also create lagged features and compute quick correlation & model-based feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7af1f55",
   "metadata": {},
   "source": [
    "# Bootstrap: ensure the 'src' package path is visible from notebooks directory\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..', 'src')))\n",
    "\n",
    "from oami.config import initialize_environment\n",
    "api_key = initialize_environment()\n",
    "print('Environment initialized. API key status:', 'set' if api_key != 'YOUR_KEY_HERE' else 'not set')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ee2b482",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from oami.data_layer import get_market_data, get_options_data\n",
    "from oami.options_features import build_options_sentiment, compute_sentiment_scores\n",
    "\n",
    "SYMBOL = 'SPY'\n",
    "START_DATE = '2024-01-01'\n",
    "END_DATE = '2024-06-30'\n",
    "\n",
    "market_df = get_market_data(\n",
    "    symbol=SYMBOL,\n",
    "    start=START_DATE,\n",
    "    end=END_DATE,\n",
    "    interval='1D',\n",
    "    use_cache=True,\n",
    "    look_forward=14,\n",
    ")\n",
    "\n",
    "options_contracts = get_options_data(\n",
    "    symbol=SYMBOL,\n",
    "    start_date=START_DATE,\n",
    "    end_date=END_DATE,\n",
    "    interval='1D',\n",
    "    use_cache=True,\n",
    "    look_forward=14,\n",
    ")\n",
    "\n",
    "options_features = build_options_sentiment(options_contracts)\n",
    "if not options_features.empty:\n",
    "    sentiment_scores = compute_sentiment_scores(options_features)\n",
    "    options_features = options_features.merge(sentiment_scores, on='Date', how='left')\n",
    "else:\n",
    "    sentiment_scores = pd.DataFrame(columns=['Date', 'option_sentiment_score', 'fear_greed_skew'])\n",
    "\n",
    "options_feature_set = options_features.sort_values('Date').reset_index(drop=True)\n",
    "market_df = market_df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "market_df.head(), options_feature_set.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c094b767",
   "metadata": {},
   "source": [
    "from typing import Iterable, List\n",
    "import ta\n",
    "\n",
    "\n",
    "def build_ta_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Create technical indicators using the ``ta`` library.\"\"\"\n",
    "    out = df.copy().sort_values('Date')\n",
    "    c, h, l, v = out['Close'], out['High'], out['Low'], out['Volume']\n",
    "\n",
    "    # Trend & momentum\n",
    "    for w in (5, 10, 20):\n",
    "        out[f'sma_{w}'] = c.rolling(w).mean()\n",
    "    for w in (10, 20):\n",
    "        out[f'ema_{w}'] = c.ewm(span=w, adjust=False).mean()\n",
    "    out['rsi_14'] = ta.momentum.RSIIndicator(close=c, window=14).rsi()\n",
    "    macd = ta.trend.MACD(close=c, window_fast=12, window_slow=26, window_sign=9)\n",
    "    out['macd'], out['macd_signal'], out['macd_hist'] = macd.macd(), macd.macd_signal(), macd.macd_diff()\n",
    "\n",
    "    # Volatility\n",
    "    bb = ta.volatility.BollingerBands(close=c, window=20, window_dev=2)\n",
    "    out['bb_width'] = bb.bollinger_wband()\n",
    "    out['atr_14'] = ta.volatility.AverageTrueRange(high=h, low=l, close=c, window=14).average_true_range()\n",
    "    for w in (10, 20):\n",
    "        out[f'roll_std_{w}'] = c.rolling(w).std()\n",
    "\n",
    "    # Volume features\n",
    "    out['vol_ma_10'] = v.rolling(10).mean()\n",
    "    out['vol_z_20'] = (v - v.rolling(20).mean()) / (v.rolling(20).std())\n",
    "\n",
    "    # Returns & target\n",
    "    out['ret_1'] = c.pct_change(1)\n",
    "    out['next_return'] = out['ret_1'].shift(-1)\n",
    "    return out\n",
    "\n",
    "\n",
    "mkt = build_ta_features(market_df)\n",
    "opt = options_feature_set.copy()\n",
    "features = pd.merge(mkt, opt, on='Date', how='left')\n",
    "features.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f345b69b",
   "metadata": {},
   "source": [
    "def make_lags(df: pd.DataFrame, cols: list, lags=(1, 3, 5, 10)) -> pd.DataFrame:\n",
    "    \"\"\"Add lagged features for selected columns.\"\"\"\n",
    "    out = df.copy().sort_values('Date')\n",
    "    for c in cols:\n",
    "        if c not in out.columns:\n",
    "            continue\n",
    "        for L in lags:\n",
    "            out[f'{c}_lag{L}'] = out[c].shift(L)\n",
    "    return out\n",
    "\n",
    "lag_columns = [\n",
    "    'ret_1',\n",
    "    'rsi_14',\n",
    "    'macd',\n",
    "    'macd_signal',\n",
    "    'bb_width',\n",
    "    'atr_14',\n",
    "    'weighted_average_moneyness',\n",
    "    'implied_direction_bias',\n",
    "    'near_far_expiry_vol_ratio',\n",
    "    'option_sentiment_score',\n",
    "    'fear_greed_skew',\n",
    "]\n",
    "\n",
    "features = make_lags(features, lag_columns)\n",
    "features = features.dropna().reset_index(drop=True)\n",
    "features.head()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "676863bd",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "numeric = features.drop(columns=['Date']).select_dtypes(include=[np.number])\n",
    "corr = numeric.corr()\n",
    "\n",
    "# Plot a correlation heatmap (matplotlib only; single chart; default colormap)\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(corr, aspect='auto')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.index)), corr.index)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5c70f48",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Clean feature matrix\n",
    "drop_cols = ['Open','High','Low','Close','Volume']\n",
    "X = features.drop(columns=[c for c in drop_cols if c in features.columns])\n",
    "X = X.drop(columns=['Date','next_return'], errors='ignore').select_dtypes(include=[np.number])\n",
    "\n",
    "# Target (optional: try next_5d_return instead)\n",
    "y = features['next_return']\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    'RandomForest': RandomForestRegressor(n_estimators=500, max_depth=10, min_samples_leaf=5, random_state=42),\n",
    "    'GradientBoosting': GradientBoostingRegressor(n_estimators=500, learning_rate=0.05, max_depth=5, random_state=42),\n",
    "    'Ridge': Ridge(alpha=0.1, fit_intercept=True)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    results[name] = r2_score(y_test, pred)\n",
    "    print(f\"{name:<18} R² = {results[name]:.6f}\")\n",
    "\n",
    "pd.DataFrame({'R2': results})\n",
    "\n",
    "\n",
    "importances = {}\n",
    "for name, model in models.items():\n",
    "    fitted_model = model\n",
    "    if hasattr(fitted_model, 'feature_importances_'):\n",
    "        importances[name] = pd.Series(fitted_model.feature_importances_, index=X.columns).sort_values(ascending=False)\n",
    "    elif hasattr(fitted_model, 'coef_'):\n",
    "        coef = getattr(fitted_model, 'coef_')\n",
    "        if coef.ndim > 1:\n",
    "            coef = coef[-1]\n",
    "        importances[name] = pd.Series(np.abs(coef), index=X.columns).sort_values(ascending=False)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8e00d83",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "for name, imp in importances.items():\n",
    "    print(f'\\nTop features — {name}')\n",
    "    display(imp.to_frame('importance'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "047d9eea",
   "metadata": {},
   "source": [
    "## ✅ Summary\n",
    "\n",
    "- Built technical indicators (SMA/EMA/RSI/MACD/BB/ATR) and volatility/volume stats from daily market data.\n",
    "- Derived options sentiment features using OCC contract OHLCV (PCR, moneyness, expiry ratios, term structure) and computed OSS + Fear-Greed Skew.\n",
    "- Created lagged predictors, visualised correlations, and benchmarked a few regression models.\n",
    "- Cached all raw inputs and contract aggregates in `data/cache/oami_store.h5` for reproducible re-runs."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
